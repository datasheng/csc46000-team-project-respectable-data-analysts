{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419e8e06",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d733cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from massive import RESTClient\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "MASSIVE_API_KEY = os.getenv(\"MASSIVE_API_KEY\")\n",
    "\n",
    "\n",
    "client = RESTClient(api_key=MASSIVE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87895ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTIPLIER = 1\n",
    "TIMESPAN = \"hour\"\n",
    "ADJUSTED = \"true\"\n",
    "SORT = \"asc\"\n",
    "LIMIT = 50000\n",
    "START = None   # Can only go back 2 years\n",
    "DIR = \"data\"\n",
    "SLEEP_TIME = 60/5   # Rate limit is 5/min\n",
    "\n",
    "os.makedirs(DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c23788",
   "metadata": {},
   "source": [
    "https://massive.com/docs/rest/stocks/tickers/all-tickers\n",
    "https://massive.com/docs/rest/stocks/aggregates/custom-bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1740fb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agg(open=88.85, high=88.85, low=88.85, close=88.85, volume=1302, vwap=88.85, timestamp=1763715600000, transactions=21, otc=None)]\n"
     ]
    }
   ],
   "source": [
    "aggs = []\n",
    "for a in client.list_aggs(\n",
    "    \"XLE\",\n",
    "    1,\n",
    "    \"hour\",\n",
    "    \"2025-11-21\",\n",
    "    \"2025-11-24\",\n",
    "    adjusted=\"true\",\n",
    "    sort=\"asc\",\n",
    "    limit=3,\n",
    "):\n",
    "    aggs.append(a)\n",
    "\n",
    "print(aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2054e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def today():\n",
    "    return datetime.now(ZoneInfo(\"America/New_York\")).date()\n",
    "\n",
    "def parse_date(string):\n",
    "    return datetime.strptime(string, \"%Y-%m-%d\").date()\n",
    "\n",
    "def clamp_date(end_date):\n",
    "    return end_date.replace(year=end_date.year - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "667208b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(bars):\n",
    "    cols = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"vwap\"]\n",
    "    if not bars:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "    \n",
    "    df = pd.DataFrame([vars(bar) for bar in bars])\n",
    "\n",
    "    df = df.drop_duplicates(subset=[\"timestamp\"], keep=\"first\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
    "\n",
    "    result = df[cols].sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e74f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_early(collected, filepath):\n",
    "    if not collected:\n",
    "        print(\"Nothing returned from API before error.\")\n",
    "        return\n",
    "    \n",
    "    df_partial = convert(collected)\n",
    "    df_partial.to_csv(filepath, index=False)\n",
    "    print(f\"Early save of ({len(df_partial)}) rows at {filepath}\")\n",
    "\n",
    "\n",
    "def fetch_data(client, ticker, start_date, end_date):\n",
    "    aggs = []\n",
    "    current_start = start_date\n",
    "\n",
    "    print(f\"Grabbing {ticker} from {start_date.isoformat()} to {end_date.isoformat()}\")\n",
    "    with tqdm(desc=\"Fetching bars\", unit=\"bars\") as pbar:\n",
    "        while current_start <= end_date:\n",
    "            try:\n",
    "                for bar in client.list_aggs(\n",
    "                    ticker, MULTIPLIER, TIMESPAN,\n",
    "                    current_start.isoformat(), end_date.isoformat(),\n",
    "                    adjusted=ADJUSTED, sort=SORT, limit=LIMIT\n",
    "                ):\n",
    "                    aggs.append(bar)\n",
    "                    pbar.update(1)\n",
    "\n",
    "                break\n",
    "\n",
    "            except Exception:\n",
    "                last_bar = aggs[-1]\n",
    "                last_date = datetime.fromtimestamp(last_bar.timestamp / 1000, tz=ZoneInfo(\"America/New_York\")).date()\n",
    "                time.sleep(SLEEP_TIME * 2)\n",
    "                current_start = last_date\n",
    "\n",
    "    return aggs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09c3fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(ticker):\n",
    "    end_date = today()\n",
    "    allowed_start = clamp_date(end_date)\n",
    "    start_date = parse_date(START) if START else allowed_start\n",
    "\n",
    "    if start_date < allowed_start:\n",
    "        print(f\"Error: {start_date} older than 2-year limit {allowed_start}\")\n",
    "        return\n",
    "\n",
    "    client = RESTClient(MASSIVE_API_KEY)\n",
    "    res = []\n",
    "\n",
    "    try:\n",
    "        res = fetch_data(client, ticker, start_date, end_date)\n",
    "        \n",
    "        df = convert(res)\n",
    "        filename = f\"{DIR}/{ticker}_full.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        \n",
    "    except Exception as exc:\n",
    "        print(f\"type: {type(exc).__name__}\")\n",
    "        print(f\"error: {exc}\")\n",
    "\n",
    "        filename = f\"{DIR}/{ticker}_early.csv\"\n",
    "        save_early(res, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16521e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing AAPL from 2023-11-26 to 2025-11-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching bars: 8019bars [01:16, 104.41bars/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing NVDA from 2023-11-26 to 2025-11-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching bars: 8037bars [02:07, 63.00bars/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing XOM from 2023-11-26 to 2025-11-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching bars: 7667bars [00:50, 150.62bars/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing JPM from 2023-11-26 to 2025-11-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching bars: 6993bars [00:50, 137.60bars/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing TSLA from 2023-11-26 to 2025-11-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching bars: 8030bars [02:06, 63.28bars/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing AMZN from 2023-11-26 to 2025-11-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching bars: 8028bars [02:05, 63.85bars/s]  \n"
     ]
    }
   ],
   "source": [
    "# Stocks\n",
    "tickers = ['AAPL', 'NVDA', \"XOM\", \"JPM\", 'TSLA', 'AMZN']\n",
    "for ticker in tickers:\n",
    "    query(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing XLF from 2023-11-26 to 2025-11-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching bars: 7881bars [00:26, 294.83bars/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing ARKK from 2023-11-26 to 2025-11-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching bars: 7782bars [01:15, 102.80bars/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing XLY from 2023-11-26 to 2025-11-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching bars: 5345bars [00:50, 105.10bars/s] \n"
     ]
    }
   ],
   "source": [
    "# ETFs\n",
    "tickers = ['XLK', 'SOXX', \"XLE\", \"XLF\", 'ARKK', 'XLY']\n",
    "for ticker in tickers:\n",
    "    query(ticker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
